{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5fa7afdb",
      "metadata": {},
      "source": [
        "This is a starter notebook for the [Kitchenware classification](https://www.kaggle.com/competitions/kitchenware-classification) competition on Kaggle\n",
        "\n",
        "To get started:\n",
        "\n",
        "- Join the competition and accept rules\n",
        "- Download your Kaggle credentials file\n",
        "- If you're running in Saturn Cloud, configure your instance to have access to access the kaggle credentials\n",
        "\n",
        "When this is done, we can download the data. We need to execute the following cell only once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66021fd7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "A subdirectory or file data already exists.\n",
            "The system cannot find the path specified.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c kitchenware-classification\n",
        "!mkdir data\n",
        "!unzip kitchenware-classification.zip -d data > /dev/null\n",
        "!rm kitchenware-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cccc3037",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93406166",
      "metadata": {},
      "source": [
        "Now let's train a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4af58b8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "05e8cdd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_SIZE = 9367\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "WORKERS = 4\n",
        "EPOCHS = 10\n",
        "\n",
        "BASE_PATH='./data'\n",
        "\n",
        "classes = [\n",
        "    'cup', \n",
        "    'fork', \n",
        "    'glass', \n",
        "    'knife', \n",
        "    'plate', \n",
        "    'spoon'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3669e2fd",
      "metadata": {},
      "source": [
        "First, we will load the training dataframe and split it into train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6dca2c5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>label</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0560</td>\n",
              "      <td>glass</td>\n",
              "      <td>data/images/0560.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4675</td>\n",
              "      <td>cup</td>\n",
              "      <td>data/images/4675.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0875</td>\n",
              "      <td>glass</td>\n",
              "      <td>data/images/0875.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4436</td>\n",
              "      <td>spoon</td>\n",
              "      <td>data/images/4436.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8265</td>\n",
              "      <td>plate</td>\n",
              "      <td>data/images/8265.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id  label              filename\n",
              "0  0560  glass  data/images/0560.jpg\n",
              "1  4675    cup  data/images/4675.jpg\n",
              "2  0875  glass  data/images/0875.jpg\n",
              "3  4436  spoon  data/images/4436.jpg\n",
              "4  8265  plate  data/images/8265.jpg"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_full = pd.read_csv('data/train.csv', dtype={'Id': str})\n",
        "df_train_full['filename'] = 'data/images/' + df_train_full['Id'] + '.jpg'\n",
        "df_train_full.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "32713ffa",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_cutoff = int(len(df_train_full) * 0.8)\n",
        "df_train = df_train_full[:val_cutoff]\n",
        "df_val = df_train_full[val_cutoff:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bfef22",
      "metadata": {},
      "source": [
        "Now let's create image generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2caa27c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c83ced9e",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4447 validated image filenames belonging to 6 classes.\n",
            "Found 1112 validated image filenames belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    df_train,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    df_val,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0f35ac7c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['cup', 'fork', 'glass', 'knife', 'plate', 'spoon'], dtype='<U5')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = np.array(list(train_generator.class_indices.keys()))\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f82948f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 patience = 5,\n",
        "                                                 mode = 'max',\n",
        "                                                 restore_best_weights = True,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "callbacks = [earlystopping]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f077d2e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/12/15 13:28:42 INFO mlflow.tracking.fluent: Experiment with name 'model_search_transformers_large' does not exist. Creating a new experiment.\n",
            "2022/12/15 13:28:42 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
          ]
        }
      ],
      "source": [
        "EXP_NAME = 'model_search_transformers_large'\n",
        "mlflow.set_experiment(EXP_NAME)\n",
        "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
        "mlflow.tensorflow.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2470ca7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_cv_attention_models import beit, efficientnet, coatnet, davit, convnext, hornet, swin_transformer_v2, maxvit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a78ce1ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>> Load pretrained from: C:\\Users\\andre\\.keras\\models\\maxvit_tiny_224_imagenet.h5\n",
            "WARNING:tensorflow:Skipping loading weights for layer #863 (named predictions) due to mismatch in shape for weight predictions/kernel:0. Weight expects shape (512, 6). Received saved weight with shape (512, 1000)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #863 (named predictions) due to mismatch in shape for weight predictions/bias:0. Weight expects shape (6,). Received saved weight with shape (1000,)\n"
          ]
        }
      ],
      "source": [
        "base_model = maxvit.MaxViT_Tiny(    # MaxViT_Small(\n",
        "    pretrained='imagenet',  #weights='imagenet',\n",
        "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "    num_classes=len(classes)\n",
        ")\n",
        "base_model.trainable = False\n",
        "base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-4].output)\n",
        "\n",
        "inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "model = tf.keras.Sequential([\n",
        "    inputs,\n",
        "    base_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(12, 'gelu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(6, 'softmax')\n",
        "],\n",
        "name = 'MaxViT_Base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9731ce4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5c20c933",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/12/15 13:28:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2022/12/15 13:28:51 INFO mlflow.store.db.utils: Updating database tables\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
            "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "556/556 [==============================] - 91s 127ms/step - loss: 0.3281 - accuracy: 0.8972 - val_loss: 0.1366 - val_accuracy: 0.9541\n",
            "Epoch 2/10\n",
            "556/556 [==============================] - 67s 121ms/step - loss: 0.2080 - accuracy: 0.9357 - val_loss: 0.1927 - val_accuracy: 0.9469\n",
            "Epoch 3/10\n",
            "556/556 [==============================] - 67s 121ms/step - loss: 0.1812 - accuracy: 0.9406 - val_loss: 0.1381 - val_accuracy: 0.9577\n",
            "Epoch 4/10\n",
            "556/556 [==============================] - 67s 121ms/step - loss: 0.1666 - accuracy: 0.9458 - val_loss: 0.1533 - val_accuracy: 0.9622\n",
            "Epoch 5/10\n",
            "556/556 [==============================] - 68s 122ms/step - loss: 0.1694 - accuracy: 0.9424 - val_loss: 0.1387 - val_accuracy: 0.9649\n",
            "Epoch 6/10\n",
            "556/556 [==============================] - 67s 121ms/step - loss: 0.1481 - accuracy: 0.9494 - val_loss: 0.2404 - val_accuracy: 0.9550\n",
            "Epoch 7/10\n",
            "556/556 [==============================] - 68s 121ms/step - loss: 0.1565 - accuracy: 0.9530 - val_loss: 0.1439 - val_accuracy: 0.9577\n",
            "Epoch 8/10\n",
            "556/556 [==============================] - 67s 121ms/step - loss: 0.1540 - accuracy: 0.9521 - val_loss: 0.1553 - val_accuracy: 0.9577\n",
            "Epoch 9/10\n",
            "545/556 [============================>.] - ETA: 1s - loss: 0.1579 - accuracy: 0.9486"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data=val_generator,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    workers=WORKERS,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "keras-attention-models",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "c8dc41aeace2424cb4569389014b2eafdc0f961eabe339db958c7b7f0a6f8b70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
