{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5fa7afdb",
      "metadata": {},
      "source": [
        "This is a starter notebook for the [Kitchenware classification](https://www.kaggle.com/competitions/kitchenware-classification) competition on Kaggle\n",
        "\n",
        "To get started:\n",
        "\n",
        "- Join the competition and accept rules\n",
        "- Download your Kaggle credentials file\n",
        "- If you're running in Saturn Cloud, configure your instance to have access to access the kaggle credentials\n",
        "\n",
        "When this is done, we can download the data. We need to execute the following cell only once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66021fd7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "A subdirectory or file data already exists.\n",
            "The system cannot find the path specified.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c kitchenware-classification\n",
        "!mkdir data\n",
        "!unzip kitchenware-classification.zip -d data > /dev/null\n",
        "!rm kitchenware-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cccc3037",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93406166",
      "metadata": {},
      "source": [
        "Now let's train a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4af58b8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "05e8cdd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_SIZE = 9367\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "WORKERS = 4\n",
        "EPOCHS = 10\n",
        "\n",
        "BASE_PATH='./data'\n",
        "\n",
        "classes = [\n",
        "    'cup', \n",
        "    'fork', \n",
        "    'glass', \n",
        "    'knife', \n",
        "    'plate', \n",
        "    'spoon'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3669e2fd",
      "metadata": {},
      "source": [
        "First, we will load the training dataframe and split it into train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6dca2c5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>label</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0560</td>\n",
              "      <td>glass</td>\n",
              "      <td>data/images/0560.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4675</td>\n",
              "      <td>cup</td>\n",
              "      <td>data/images/4675.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0875</td>\n",
              "      <td>glass</td>\n",
              "      <td>data/images/0875.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4436</td>\n",
              "      <td>spoon</td>\n",
              "      <td>data/images/4436.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8265</td>\n",
              "      <td>plate</td>\n",
              "      <td>data/images/8265.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id  label              filename\n",
              "0  0560  glass  data/images/0560.jpg\n",
              "1  4675    cup  data/images/4675.jpg\n",
              "2  0875  glass  data/images/0875.jpg\n",
              "3  4436  spoon  data/images/4436.jpg\n",
              "4  8265  plate  data/images/8265.jpg"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_full = pd.read_csv('data/train.csv', dtype={'Id': str})\n",
        "df_train_full['filename'] = 'data/images/' + df_train_full['Id'] + '.jpg'\n",
        "df_train_full.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "32713ffa",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_cutoff = int(len(df_train_full) * 0.8)\n",
        "df_train = df_train_full[:val_cutoff]\n",
        "df_val = df_train_full[val_cutoff:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bfef22",
      "metadata": {},
      "source": [
        "Now let's create image generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2caa27c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c83ced9e",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4447 validated image filenames belonging to 6 classes.\n",
            "Found 1112 validated image filenames belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    df_train,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    df_val,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0f35ac7c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['cup', 'fork', 'glass', 'knife', 'plate', 'spoon'], dtype='<U5')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = np.array(list(train_generator.class_indices.keys()))\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f82948f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 patience = 5,\n",
        "                                                 mode = 'max',\n",
        "                                                 restore_best_weights = True,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "callbacks = [earlystopping]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f077d2e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "EXP_NAME = 'model_search_transformers_large'\n",
        "mlflow.set_experiment(EXP_NAME)\n",
        "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
        "mlflow.tensorflow.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2470ca7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_cv_attention_models import beit, efficientnet, coatnet, davit, convnext, hornet, swin_transformer_v2, maxvit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416ccb4c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>> Load pretrained from: C:\\Users\\andre\\.keras\\models\\beit_large_patch16_224_imagenet21k-ft1k.h5\n",
            "WARNING:tensorflow:Skipping loading weights for layer #679 (named predictions) due to mismatch in shape for weight predictions/kernel:0. Weight expects shape (1024, 6). Received saved weight with shape (1024, 1000)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #679 (named predictions) due to mismatch in shape for weight predictions/bias:0. Weight expects shape (6,). Received saved weight with shape (1000,)\n"
          ]
        }
      ],
      "source": [
        "base_model = beit.BeitLargePatch16( #BeitBasePatch16(\n",
        "    pretrained='imagenet21k-ft1k',  #weights='imagenet',\n",
        "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "    num_classes=len(classes)\n",
        ")\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e34cdac3",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-3].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d56e11",
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    inputs,\n",
        "    base_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(12, 'gelu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(6, 'softmax')\n",
        "],\n",
        "name = 'efficientnet2_xl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a7a80f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e846ae7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "556/556 [==============================] - 140s 217ms/step - loss: 0.2007 - accuracy: 0.9445 - val_loss: 0.0806 - val_accuracy: 0.9793\n",
            "Epoch 2/2\n",
            "423/556 [=====================>........] - ETA: 21s - loss: 0.1085 - accuracy: 0.9642"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee6e149",
      "metadata": {},
      "source": [
        "Now let's use this model to predict the labels for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40643e85",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0678</td>\n",
              "      <td>data/images/0678.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3962</td>\n",
              "      <td>data/images/3962.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9271</td>\n",
              "      <td>data/images/9271.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5133</td>\n",
              "      <td>data/images/5133.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8842</td>\n",
              "      <td>data/images/8842.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id              filename\n",
              "0  0678  data/images/0678.jpg\n",
              "1  3962  data/images/3962.jpg\n",
              "2  9271  data/images/9271.jpg\n",
              "3  5133  data/images/5133.jpg\n",
              "4  8842  data/images/8842.jpg"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.read_csv('data/test.csv', dtype={'Id': str})\n",
        "df_test['filename'] = 'data/images/' + df_test['Id'] + '.jpg'\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd96ab0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3808 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    df_test,\n",
        "    x_col='filename',\n",
        "    class_mode='input',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e279456f",
      "metadata": {},
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node 'beit_transformer/flatten/Reshape' defined at (most recent call last):\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_3864\\1876619750.py\", line 1, in <module>\n      y_pred = model.predict(test_generator)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n      result = self._call(*args, **kwds)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 963, in _call\n      self._initialize(args, kwds, add_initializers_to=initializers)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 785, in _initialize\n      self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2523, in _get_concrete_function_internal_garbage_collected\n      graph_function, _ = self._maybe_define_function(args, kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2760, in _maybe_define_function\n      graph_function = self._create_graph_function(args, kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2670, in _create_graph_function\n      func_graph_module.func_graph_from_py_func(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1247, in func_graph_from_py_func\n      func_outputs = python_func(*func_args, **func_kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 677, in wrapped_fn\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1222, in autograph_handler\n      return autograph.converted_call(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1315, in run\n      return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 2891, in call_for_each_replica\n      return self._call_for_each_replica(fn, args, kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 3692, in _call_for_each_replica\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\layers\\reshaping\\flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 199, in reshape\n      result = gen_array_ops.reshape(tensor, shape, name)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 8550, in reshape\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 735, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n      ret = Operation(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2108, in __init__\n      c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1974, in _create_c_op\n      tf_stack.extract_stack_for_op(c_op, stacklevel=3)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\tf_stack.py\", line 180, in extract_stack_for_op\n      _tf_stack.extract_stack_for_op(\nNode: 'beit_transformer/flatten/Reshape'\nInput to reshape is a tensor with 1024000 values, but the requested shape requires a multiple of 62720\n\t [[{{node beit_transformer/flatten/Reshape}}]] [Op:__inference_predict_function_96606]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(test_generator)\n",
            "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'beit_transformer/flatten/Reshape' defined at (most recent call last):\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_3864\\1876619750.py\", line 1, in <module>\n      y_pred = model.predict(test_generator)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n      result = self._call(*args, **kwds)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 963, in _call\n      self._initialize(args, kwds, add_initializers_to=initializers)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 785, in _initialize\n      self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2523, in _get_concrete_function_internal_garbage_collected\n      graph_function, _ = self._maybe_define_function(args, kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2760, in _maybe_define_function\n      graph_function = self._create_graph_function(args, kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2670, in _create_graph_function\n      func_graph_module.func_graph_from_py_func(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1247, in func_graph_from_py_func\n      func_outputs = python_func(*func_args, **func_kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 677, in wrapped_fn\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1222, in autograph_handler\n      return autograph.converted_call(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1315, in run\n      return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 2891, in call_for_each_replica\n      return self._call_for_each_replica(fn, args, kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 3692, in _call_for_each_replica\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\keras\\layers\\reshaping\\flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 199, in reshape\n      result = gen_array_ops.reshape(tensor, shape, name)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 8550, in reshape\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 735, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n      ret = Operation(\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2108, in __init__\n      c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1974, in _create_c_op\n      tf_stack.extract_stack_for_op(c_op, stacklevel=3)\n    File \"c:\\Users\\andre\\anaconda3\\envs\\keras-attention-models\\lib\\site-packages\\tensorflow\\python\\util\\tf_stack.py\", line 180, in extract_stack_for_op\n      _tf_stack.extract_stack_for_op(\nNode: 'beit_transformer/flatten/Reshape'\nInput to reshape is a tensor with 1024000 values, but the requested shape requires a multiple of 62720\n\t [[{{node beit_transformer/flatten/Reshape}}]] [Op:__inference_predict_function_96606]"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3f8017",
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = classes[y_pred.argmax(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0194490",
      "metadata": {},
      "source": [
        "Finally, we need to prepare the submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da13e38c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission = pd.DataFrame()\n",
        "df_submission['filename'] = test_generator.filenames\n",
        "df_submission['label'] = predictions\n",
        "\n",
        "df_submission['Id'] = df_submission.filename.str[len('data/images/'):-4]\n",
        "del df_submission['filename']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3822fafd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission[['Id', 'label']].to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5081abc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !kaggle competitions submit kitchenware-classification -f submission.csv -m 'validation: 0.8570'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ad10a4",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "keras-attention-models",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "c8dc41aeace2424cb4569389014b2eafdc0f961eabe339db958c7b7f0a6f8b70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
