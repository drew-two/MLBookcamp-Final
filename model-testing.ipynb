{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kitchenware Classification Model Search\n",
    "\n",
    "Searching for best CNN model for [Kitchenware classification](https://www.kaggle.com/competitions/kitchenware-classification) competition on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, pickle\n",
    "from math import log10, floor\n",
    "\n",
    "import mlflow \n",
    "import keras_tuner\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.applications import imagenet_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 9367\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "WORKERS = 4\n",
    "EPOCHS = 10\n",
    "\n",
    "BASE_PATH='./data'\n",
    "\n",
    "classes = [\n",
    "    'cup', \n",
    "    'fork', \n",
    "    'glass', \n",
    "    'knife', \n",
    "    'plate', \n",
    "    'spoon'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training data and splitting into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0560</td>\n",
       "      <td>glass</td>\n",
       "      <td>./data/images/0560.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4675</td>\n",
       "      <td>cup</td>\n",
       "      <td>./data/images/4675.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0875</td>\n",
       "      <td>glass</td>\n",
       "      <td>./data/images/0875.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4436</td>\n",
       "      <td>spoon</td>\n",
       "      <td>./data/images/4436.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8265</td>\n",
       "      <td>plate</td>\n",
       "      <td>./data/images/8265.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  label                filename\n",
       "0  0560  glass  ./data/images/0560.jpg\n",
       "1  4675    cup  ./data/images/4675.jpg\n",
       "2  0875  glass  ./data/images/0875.jpg\n",
       "3  4436  spoon  ./data/images/4436.jpg\n",
       "4  8265  plate  ./data/images/8265.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full = pd.read_csv(BASE_PATH + '/train.csv', dtype={'Id': str})\n",
    "df_train_full['filename'] = BASE_PATH + '/images/' + df_train_full['Id'] + '.jpg'\n",
    "df_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cutoff = int(len(df_train_full) * 0.8)\n",
    "df_train = df_train_full[:val_cutoff]\n",
    "df_val = df_train_full[val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.applications as applications\n",
    "from keras_cv_attention_models import beit, davit, efficientnet, convnext, hornet, swin_transformer_v2, maxvit\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Search\n",
    "\n",
    "Function for getting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name='Xception'):\n",
    "    if name == 'EfficientNetB7':\n",
    "        base_model = applications.efficientnet.EfficientNetB7(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "        )\n",
    "    elif name == 'EfficientNetV2L':\n",
    "        base_model = applications.efficientnet_v2.EfficientNetV2L(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "        )\n",
    "    elif name == 'ConvNeXtXLarge':\n",
    "        base_model = applications.convnext.ConvNeXtXLarge(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "        )\n",
    "    elif name == 'BeitLargePatch16':     ############################################################ LARGER TRANSFORMERS\n",
    "        base_model = beit.BeitLargePatch16( #BeitBasePatch16(\n",
    "            pretrained='imagenet21k-ft1k',  #weights='imagenet',\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            num_classes=len(classes)\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-3].output)\n",
    "    elif name == 'ConvNeXtXLarge-21k':\n",
    "        base_model = convnext.ConvNeXtXlarge( # ConvNeXtXlarge(\n",
    "            pretrained='imagenet21k-ft1k',  #weights='imagenet',\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            num_classes=len(classes)\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-4].output)\n",
    "    elif name == 'HorNetLargeGF':\n",
    "        base_model = hornet.HorNetLargeGF(    #HorNetBaseGF(\n",
    "            pretrained='imagenet22k',  #weights='imagenet',\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            num_classes=len(classes)\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-4].output)\n",
    "    elif name == 'EfficientNetV1B7':    ############################################################ EVEN LARGER TRANSFORMERS\n",
    "        base_model = efficientnet.EfficientNetV1B7(  # EfficientNetV1L2(\n",
    "            pretrained='noisy_student',  #weights='imagenet',\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            num_classes=len(classes)\n",
    "        )\n",
    "        base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-4].output)\n",
    "    elif name == 'SwinTransformerV2Base_window16':\n",
    "        base_model = swin_transformer_v2.SwinTransformerV2Base_window16(    # SwinTransformerV2Large_window16(\n",
    "            pretrained='imagenet22k',  #weights='imagenet',\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            num_classes=len(classes)\n",
    "        )\n",
    "        base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-4].output)\n",
    "    elif name == 'MaxViT_Base':\n",
    "        base_model = maxvit.MaxViT_Base(    # MaxViT_Small(\n",
    "            pretrained='imagenet21k-ft1k',  #weights='imagenet',\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            num_classes=len(classes)\n",
    "        )\n",
    "        base_model = tf.keras.Model(inputs=base_model.layers[1].input, outputs= base_model.layers[-4].output)\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These models don't have the imagenet preprocessing built in so I have to apply this\n",
    "def preprocess_input(x, data_format=None):\n",
    "    return imagenet_utils.preprocess_input(\n",
    "        x, data_format=data_format, mode=\"tf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datagen(params={}):\n",
    "    \n",
    "    image_size = params.get('image_size', IMAGE_SIZE)\n",
    "    batch_size = params.get('batch_size', BATCH_SIZE)\n",
    "\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input, \n",
    "        rotation_range=params.get('rotation_range', 0),\n",
    "        width_shift_range=params.get('trans_width_range', 0.0),\n",
    "        height_shift_range=params.get('trans_height_range', 0.0),\n",
    "        shear_range=params.get('shear_range', 0.0),\n",
    "        zoom_range=params.get('zoom_range', 0),\n",
    "        horizontal_flip=params.get('horizontal_flip', False),\n",
    "        vertical_flip=params.get('vertical_flip', False),\n",
    "        dtype=\"float16\"\n",
    "    )\n",
    "\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input, \n",
    "        dtype=\"float16\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_dataframe(\n",
    "        df_train,\n",
    "        x_col='filename',\n",
    "        y_col='label',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    val_gen = val_datagen.flow_from_dataframe(\n",
    "        df_val,\n",
    "        x_col='filename',\n",
    "        y_col='label',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras tuner function for building model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):    \n",
    "    # Getting model\n",
    "    hp_model = hp.Choice('model', ['EfficientNetB7', 'EfficientNetV2L', 'ConvNeXtXLarge'])    ## Conv models\n",
    "    # hp_model = hp.Choice('model', ['BeitLargePatch16', 'ConvNeXtXLarge-21k'])#, 'HorNetLargeGF'])  ## Transformers + Conv\n",
    "\n",
    "    base_model = get_model(hp_model)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "    if base_model.name.lower().startswith('efficientnet'):\n",
    "        model = tf.keras.Sequential([\n",
    "            inputs,\n",
    "            base_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            tf.keras.layers.Dense(12, 'gelu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            tf.keras.layers.Dense(6, 'softmax')\n",
    "        ],\n",
    "        name = hp_model)\n",
    "    else:\n",
    "        model = tf.keras.Sequential([\n",
    "            inputs,\n",
    "            base_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(12, 'gelu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(6, 'softmax')\n",
    "        ],\n",
    "        name = hp_model)\n",
    "\n",
    "    # Getting optimizer\n",
    "    learning_rate = 0.01\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling                              \n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                                 factor = 0.2,\n",
    "                                                 patience = 2,\n",
    "                                                 verbose = 1,\n",
    "                                                 min_delta = 1e-4,\n",
    "                                                 min_lr = 1e-6,\n",
    "                                                 mode = 'max')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                                 min_delta = 1e-4,\n",
    "                                                 patience = 5,\n",
    "                                                 mode = 'max',\n",
    "                                                 restore_best_weights = True,\n",
    "                                                 verbose = 1)\n",
    "\n",
    "callbacks = [earlystopping]#, reduce_lr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search over transformer and CNN models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/15 14:22:55 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project kt_model_search_transformers\\kt_model_search_transformers\\oracle.json\n",
      ">>>> Load pretrained from: C:\\Users\\andre\\.keras\\models\\beit_large_patch16_224_imagenet21k-ft1k.h5\n",
      "WARNING:tensorflow:Skipping loading weights for layer #679 (named predictions) due to mismatch in shape for weight predictions/kernel:0. Weight expects shape (1024, 6). Received saved weight with shape (1024, 1000)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #679 (named predictions) due to mismatch in shape for weight predictions/bias:0. Weight expects shape (6,). Received saved weight with shape (1000,)\n",
      "Search space summary\n",
      "Default search space size: 1\n",
      "model (Choice)\n",
      "{'default': 'BeitLargePatch16', 'conditions': [], 'values': ['BeitLargePatch16', 'ConvNeXtXLarge-21k', 'HorNetLargeGF'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "EXP_NAME = 'model_search_transformers'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory='kt_' + EXP_NAME,\n",
    "    tuner_id='kt_' + EXP_NAME,\n",
    "    project_name='kt_' + EXP_NAME,\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4447 validated image filenames belonging to 6 classes.\n",
      "Found 1112 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen = get_datagen({})\n",
    "\n",
    "# tuner.search(x = train_gen,\n",
    "#             validation_data=val_gen,\n",
    "#             batch_size=BATCH_SIZE,\n",
    "#             epochs=EPOCHS,\n",
    "#             workers=WORKERS,\n",
    "#             callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in kt_model_search_transformers\\kt_model_search_transformers\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000023BC351F2B0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "model: BeitLargePatch16\n",
      "Score: 0.9856114983558655\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "model: ConvNeXtXLarge-21k\n",
      "Score: 0.9793165326118469\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.results_summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search over CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/15 14:23:05 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 1\n",
      "model (Choice)\n",
      "{'default': 'EfficientNetB7', 'conditions': [], 'values': ['EfficientNetB7', 'EfficientNetV2L', 'ConvNeXtXLarge'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "EXP_NAME = 'model_search'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory='kt_' + EXP_NAME,\n",
    "    tuner_id='kt_' + EXP_NAME,\n",
    "    project_name='kt_' + EXP_NAME,\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4447 validated image filenames belonging to 6 classes.\n",
      "Found 1112 validated image filenames belonging to 6 classes.\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "ConvNeXtXLarge    |?                 |model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/15 14:23:24 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ad2f890f95324fd98067b3cc6ec21bf7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "516/556 [==========================>...] - ETA: 6s - loss: 0.6547 - accuracy: 0.7739"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen = get_datagen({})\n",
    "\n",
    "tuner.search(x = train_gen,\n",
    "            validation_data=val_gen,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            workers=WORKERS,\n",
    "            callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in kt_model_search\\kt_model_search\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000024A7840E5E0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "model: ConvNeXtXLarge\n",
      "Score: 0.4298561215400696\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "model: EfficientNetB7\n",
      "Score: 0.216726616024971\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "model: EfficientNetV2L\n",
      "Score: 0.2032374143600464\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.results_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-attention-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8dc41aeace2424cb4569389014b2eafdc0f961eabe339db958c7b7f0a6f8b70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
